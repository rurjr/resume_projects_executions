{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпортуєм потрібний датасет\n",
        "df = pd.read_csv('data.csv')\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>grade</th>\n      <th>emp_length</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>loan_status</th>\n      <th>dti</th>\n      <th>delinq_2yrs</th>\n      <th>...</th>\n      <th>total_rec_late_fee</th>\n      <th>recoveries</th>\n      <th>collection_recovery_fee</th>\n      <th>last_pymnt_amnt</th>\n      <th>collections_12_mths_ex_med</th>\n      <th>application_type</th>\n      <th>acc_now_delinq</th>\n      <th>tot_coll_amt</th>\n      <th>tot_cur_bal</th>\n      <th>total_rev_hi_lim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24000</td>\n      <td>10.49</td>\n      <td>779.95</td>\n      <td>B</td>\n      <td>3 years</td>\n      <td>MORTGAGE</td>\n      <td>89000.0</td>\n      <td>Fully Paid</td>\n      <td>21.12</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>78.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>16901.45</td>\n      <td>1.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>70116.0</td>\n      <td>43670.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15000</td>\n      <td>21.49</td>\n      <td>409.95</td>\n      <td>D</td>\n      <td>NaN</td>\n      <td>RENT</td>\n      <td>38251.2</td>\n      <td>Charged Off</td>\n      <td>30.98</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1614.60</td>\n      <td>145.314</td>\n      <td>409.95</td>\n      <td>1.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>273.0</td>\n      <td>31306.0</td>\n      <td>21600.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24000</td>\n      <td>6.97</td>\n      <td>740.73</td>\n      <td>A</td>\n      <td>2 years</td>\n      <td>MORTGAGE</td>\n      <td>92000.0</td>\n      <td>Fully Paid</td>\n      <td>16.57</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>12074.88</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>196318.0</td>\n      <td>68900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6500</td>\n      <td>19.22</td>\n      <td>238.99</td>\n      <td>D</td>\n      <td>4 years</td>\n      <td>MORTGAGE</td>\n      <td>25000.0</td>\n      <td>Charged Off</td>\n      <td>9.70</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>127.05</td>\n      <td>22.869</td>\n      <td>238.99</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6848.0</td>\n      <td>16700.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20000</td>\n      <td>11.22</td>\n      <td>656.86</td>\n      <td>B</td>\n      <td>10+ years</td>\n      <td>OWN</td>\n      <td>58000.0</td>\n      <td>Fully Paid</td>\n      <td>16.59</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>20101.30</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426287.0</td>\n      <td>26100.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19495</th>\n      <td>26000</td>\n      <td>14.08</td>\n      <td>606.06</td>\n      <td>C</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>80000.0</td>\n      <td>Fully Paid</td>\n      <td>8.62</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>26244.05</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>4812.0</td>\n      <td>110260.0</td>\n      <td>20600.0</td>\n    </tr>\n    <tr>\n      <th>19496</th>\n      <td>3000</td>\n      <td>12.74</td>\n      <td>100.71</td>\n      <td>C</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>109000.0</td>\n      <td>Fully Paid</td>\n      <td>34.29</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2978.46</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>260585.0</td>\n      <td>46600.0</td>\n    </tr>\n    <tr>\n      <th>19497</th>\n      <td>17000</td>\n      <td>11.12</td>\n      <td>557.53</td>\n      <td>B</td>\n      <td>7 years</td>\n      <td>MORTGAGE</td>\n      <td>75000.0</td>\n      <td>Fully Paid</td>\n      <td>20.77</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2785.60</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19498</th>\n      <td>30000</td>\n      <td>8.18</td>\n      <td>942.59</td>\n      <td>B</td>\n      <td>7 years</td>\n      <td>RENT</td>\n      <td>175000.0</td>\n      <td>Fully Paid</td>\n      <td>7.19</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>3.80</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>88348.0</td>\n      <td>48000.0</td>\n    </tr>\n    <tr>\n      <th>19499</th>\n      <td>2000</td>\n      <td>11.99</td>\n      <td>66.42</td>\n      <td>C</td>\n      <td>&lt; 1 year</td>\n      <td>RENT</td>\n      <td>41000.0</td>\n      <td>Fully Paid</td>\n      <td>13.60</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>1978.17</td>\n      <td>0.0</td>\n      <td>Individual</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18342.0</td>\n      <td>33400.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19500 rows × 31 columns</p>\n</div>",
            "text/plain": "       loan_amnt  int_rate  installment grade emp_length home_ownership  \\\n0          24000     10.49       779.95     B    3 years       MORTGAGE   \n1          15000     21.49       409.95     D        NaN           RENT   \n2          24000      6.97       740.73     A    2 years       MORTGAGE   \n3           6500     19.22       238.99     D    4 years       MORTGAGE   \n4          20000     11.22       656.86     B  10+ years            OWN   \n...          ...       ...          ...   ...        ...            ...   \n19495      26000     14.08       606.06     C  10+ years       MORTGAGE   \n19496       3000     12.74       100.71     C  10+ years       MORTGAGE   \n19497      17000     11.12       557.53     B    7 years       MORTGAGE   \n19498      30000      8.18       942.59     B    7 years           RENT   \n19499       2000     11.99        66.42     C   < 1 year           RENT   \n\n       annual_inc  loan_status    dti  delinq_2yrs  ...  total_rec_late_fee  \\\n0         89000.0   Fully Paid  21.12          1.0  ...                78.0   \n1         38251.2  Charged Off  30.98          0.0  ...                 0.0   \n2         92000.0   Fully Paid  16.57          0.0  ...                 0.0   \n3         25000.0  Charged Off   9.70          0.0  ...                15.0   \n4         58000.0   Fully Paid  16.59          0.0  ...                 0.0   \n...           ...          ...    ...          ...  ...                 ...   \n19495     80000.0   Fully Paid   8.62          0.0  ...                 0.0   \n19496    109000.0   Fully Paid  34.29          1.0  ...                 0.0   \n19497     75000.0   Fully Paid  20.77          0.0  ...                 0.0   \n19498    175000.0   Fully Paid   7.19          2.0  ...                 0.0   \n19499     41000.0   Fully Paid  13.60          1.0  ...                 0.0   \n\n       recoveries  collection_recovery_fee  last_pymnt_amnt  \\\n0            0.00                    0.000         16901.45   \n1         1614.60                  145.314           409.95   \n2            0.00                    0.000         12074.88   \n3          127.05                   22.869           238.99   \n4            0.00                    0.000         20101.30   \n...           ...                      ...              ...   \n19495        0.00                    0.000         26244.05   \n19496        0.00                    0.000          2978.46   \n19497        0.00                    0.000          2785.60   \n19498        0.00                    0.000             3.80   \n19499        0.00                    0.000          1978.17   \n\n       collections_12_mths_ex_med  application_type  acc_now_delinq  \\\n0                             1.0        Individual             0.0   \n1                             1.0        Individual             0.0   \n2                             0.0        Individual             0.0   \n3                             0.0        Individual             0.0   \n4                             0.0        Individual             0.0   \n...                           ...               ...             ...   \n19495                         0.0        Individual             0.0   \n19496                         0.0        Individual             0.0   \n19497                         0.0        Individual             0.0   \n19498                         0.0        Individual             0.0   \n19499                         0.0        Individual             0.0   \n\n       tot_coll_amt  tot_cur_bal  total_rev_hi_lim  \n0               0.0      70116.0           43670.0  \n1             273.0      31306.0           21600.0  \n2               0.0     196318.0           68900.0  \n3               0.0       6848.0           16700.0  \n4               0.0     426287.0           26100.0  \n...             ...          ...               ...  \n19495        4812.0     110260.0           20600.0  \n19496           0.0     260585.0           46600.0  \n19497           NaN          NaN               NaN  \n19498           0.0      88348.0           48000.0  \n19499           0.0      18342.0           33400.0  \n\n[19500 rows x 31 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Інформація про дата сет\n",
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19500 entries, 0 to 19499\nData columns (total 31 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   loan_amnt                   19500 non-null  int64  \n 1   int_rate                    19500 non-null  float64\n 2   installment                 19500 non-null  float64\n 3   grade                       19500 non-null  object \n 4   emp_length                  18281 non-null  object \n 5   home_ownership              19500 non-null  object \n 6   annual_inc                  19500 non-null  float64\n 7   loan_status                 19500 non-null  object \n 8   dti                         19495 non-null  float64\n 9   delinq_2yrs                 19500 non-null  float64\n 10  inq_last_6mths              19500 non-null  float64\n 11  mths_since_last_delinq      9868 non-null   float64\n 12  open_acc                    19500 non-null  float64\n 13  pub_rec                     19500 non-null  float64\n 14  revol_bal                   19500 non-null  int64  \n 15  revol_util                  19486 non-null  float64\n 16  total_acc                   19500 non-null  float64\n 17  total_pymnt                 19500 non-null  float64\n 18  total_pymnt_inv             19500 non-null  float64\n 19  total_rec_prncp             19500 non-null  float64\n 20  total_rec_int               19500 non-null  float64\n 21  total_rec_late_fee          19500 non-null  float64\n 22  recoveries                  19500 non-null  float64\n 23  collection_recovery_fee     19500 non-null  float64\n 24  last_pymnt_amnt             19500 non-null  float64\n 25  collections_12_mths_ex_med  19500 non-null  float64\n 26  application_type            19500 non-null  object \n 27  acc_now_delinq              19500 non-null  float64\n 28  tot_coll_amt                18630 non-null  float64\n 29  tot_cur_bal                 18630 non-null  float64\n 30  total_rev_hi_lim            18630 non-null  float64\ndtypes: float64(24), int64(2), object(5)\nmemory usage: 4.6+ MB\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Перевіряємо чи є неповні дані у датасеті\n",
        "df.isna().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "loan_amnt                        0\nint_rate                         0\ninstallment                      0\ngrade                            0\nemp_length                    1219\nhome_ownership                   0\nannual_inc                       0\nloan_status                      0\ndti                              5\ndelinq_2yrs                      0\ninq_last_6mths                   0\nmths_since_last_delinq        9632\nopen_acc                         0\npub_rec                          0\nrevol_bal                        0\nrevol_util                      14\ntotal_acc                        0\ntotal_pymnt                      0\ntotal_pymnt_inv                  0\ntotal_rec_prncp                  0\ntotal_rec_int                    0\ntotal_rec_late_fee               0\nrecoveries                       0\ncollection_recovery_fee          0\nlast_pymnt_amnt                  0\ncollections_12_mths_ex_med       0\napplication_type                 0\nacc_now_delinq                   0\ntot_coll_amt                   870\ntot_cur_bal                    870\ntotal_rev_hi_lim               870\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Розділяєм ознаки на числові і категоріальні\n",
        "text_features = [i for i in df.columns if type(df[i][0]) == str]\n",
        "nums_features = [i for i in df.columns if i not in text_features]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# візуалізуємо outliers\n",
        "df.boxplot(figsize=(30,10))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<Axes: >"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 3000x1000 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 2"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# створюємо цільову змінну\n",
        "loan_stat = [i for i in df['loan_status']]\n",
        "loan_stat_num = []\n",
        "for i in loan_stat:\n",
        "    if i == 'Charged Off':\n",
        "        loan_stat_num.append(1)\n",
        "    else:\n",
        "        loan_stat_num.append(0)\n",
        "    \n",
        "df['y_reg'] = loan_stat_num"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Розглянемо кореляцію  цільвої змінної і числових ознак\n",
        "plt.figure(figsize=(25,25))\n",
        "sns.heatmap(df.corr( numeric_only=True ),annot=True,cmap=\"crest\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<Axes: >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x = 'y_reg', y = 'recoveries' , data = df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "<Axes: xlabel='y_reg', ylabel='recoveries'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#розпреділення цільової змінної\n",
        "sns.histplot(df,x='y_reg',color='#abcdef')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "<Axes: xlabel='y_reg', ylabel='recoveries'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Приводим всі колонки дата фрейму до числового вигляду за допомогою OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
        "\n",
        "\n",
        "columns_ohe = make_column_transformer(\n",
        "    ( OneHotEncoder(handle_unknown='ignore',sparse_output=False) , text_features),\n",
        "    remainder = 'passthrough'\n",
        ").set_output(transform='pandas')\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Отримуємо навчальну вибірку яка повністю складений з  ознак у числовому вигляді\n",
        "df_ohe = columns_ohe.fit_transform(df)\n",
        "df_ohe = df_ohe.drop(columns=['onehotencoder__home_ownership_ANY','onehotencoder__home_ownership_OTHER',       'onehotencoder__loan_status_Charged Off',\n",
        "       'onehotencoder__loan_status_Fully Paid',\n",
        "       'onehotencoder__loan_status_In Grace Period',\n",
        "       'onehotencoder__loan_status_Late (16-30 days)',\n",
        "       'onehotencoder__loan_status_Late (31-120 days)','remainder__y_reg'])\n",
        "df_ohe\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>onehotencoder__grade_A</th>\n      <th>onehotencoder__grade_B</th>\n      <th>onehotencoder__grade_C</th>\n      <th>onehotencoder__grade_D</th>\n      <th>onehotencoder__grade_E</th>\n      <th>onehotencoder__grade_F</th>\n      <th>onehotencoder__grade_G</th>\n      <th>onehotencoder__emp_length_1 year</th>\n      <th>onehotencoder__emp_length_10+ years</th>\n      <th>onehotencoder__emp_length_2 years</th>\n      <th>...</th>\n      <th>remainder__total_rec_int</th>\n      <th>remainder__total_rec_late_fee</th>\n      <th>remainder__recoveries</th>\n      <th>remainder__collection_recovery_fee</th>\n      <th>remainder__last_pymnt_amnt</th>\n      <th>remainder__collections_12_mths_ex_med</th>\n      <th>remainder__acc_now_delinq</th>\n      <th>remainder__tot_coll_amt</th>\n      <th>remainder__tot_cur_bal</th>\n      <th>remainder__total_rev_hi_lim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3359.33</td>\n      <td>78.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>16901.45</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>70116.0</td>\n      <td>43670.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5302.70</td>\n      <td>0.0</td>\n      <td>1614.60</td>\n      <td>145.314</td>\n      <td>409.95</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>273.0</td>\n      <td>31306.0</td>\n      <td>21600.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2148.75</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>12074.88</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>196318.0</td>\n      <td>68900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2109.37</td>\n      <td>15.0</td>\n      <td>127.05</td>\n      <td>22.869</td>\n      <td>238.99</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6848.0</td>\n      <td>16700.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>88.83</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>20101.30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426287.0</td>\n      <td>26100.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19495</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>223.71</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>26244.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4812.0</td>\n      <td>110260.0</td>\n      <td>20600.0</td>\n    </tr>\n    <tr>\n      <th>19496</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>77.05</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2978.46</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>260585.0</td>\n      <td>46600.0</td>\n    </tr>\n    <tr>\n      <th>19497</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3020.67</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2785.60</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19498</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3909.77</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>3.80</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>88348.0</td>\n      <td>48000.0</td>\n    </tr>\n    <tr>\n      <th>19499</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>43.26</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>1978.17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18342.0</td>\n      <td>33400.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19500 rows × 50 columns</p>\n</div>",
            "text/plain": "       onehotencoder__grade_A  onehotencoder__grade_B  onehotencoder__grade_C  \\\n0                         0.0                     1.0                     0.0   \n1                         0.0                     0.0                     0.0   \n2                         1.0                     0.0                     0.0   \n3                         0.0                     0.0                     0.0   \n4                         0.0                     1.0                     0.0   \n...                       ...                     ...                     ...   \n19495                     0.0                     0.0                     1.0   \n19496                     0.0                     0.0                     1.0   \n19497                     0.0                     1.0                     0.0   \n19498                     0.0                     1.0                     0.0   \n19499                     0.0                     0.0                     1.0   \n\n       onehotencoder__grade_D  onehotencoder__grade_E  onehotencoder__grade_F  \\\n0                         0.0                     0.0                     0.0   \n1                         1.0                     0.0                     0.0   \n2                         0.0                     0.0                     0.0   \n3                         1.0                     0.0                     0.0   \n4                         0.0                     0.0                     0.0   \n...                       ...                     ...                     ...   \n19495                     0.0                     0.0                     0.0   \n19496                     0.0                     0.0                     0.0   \n19497                     0.0                     0.0                     0.0   \n19498                     0.0                     0.0                     0.0   \n19499                     0.0                     0.0                     0.0   \n\n       onehotencoder__grade_G  onehotencoder__emp_length_1 year  \\\n0                         0.0                               0.0   \n1                         0.0                               0.0   \n2                         0.0                               0.0   \n3                         0.0                               0.0   \n4                         0.0                               0.0   \n...                       ...                               ...   \n19495                     0.0                               0.0   \n19496                     0.0                               0.0   \n19497                     0.0                               0.0   \n19498                     0.0                               0.0   \n19499                     0.0                               0.0   \n\n       onehotencoder__emp_length_10+ years  onehotencoder__emp_length_2 years  \\\n0                                      0.0                                0.0   \n1                                      0.0                                0.0   \n2                                      0.0                                1.0   \n3                                      0.0                                0.0   \n4                                      1.0                                0.0   \n...                                    ...                                ...   \n19495                                  1.0                                0.0   \n19496                                  1.0                                0.0   \n19497                                  0.0                                0.0   \n19498                                  0.0                                0.0   \n19499                                  0.0                                0.0   \n\n       ...  remainder__total_rec_int  remainder__total_rec_late_fee  \\\n0      ...                   3359.33                           78.0   \n1      ...                   5302.70                            0.0   \n2      ...                   2148.75                            0.0   \n3      ...                   2109.37                           15.0   \n4      ...                     88.83                            0.0   \n...    ...                       ...                            ...   \n19495  ...                    223.71                            0.0   \n19496  ...                     77.05                            0.0   \n19497  ...                   3020.67                            0.0   \n19498  ...                   3909.77                            0.0   \n19499  ...                     43.26                            0.0   \n\n       remainder__recoveries  remainder__collection_recovery_fee  \\\n0                       0.00                               0.000   \n1                    1614.60                             145.314   \n2                       0.00                               0.000   \n3                     127.05                              22.869   \n4                       0.00                               0.000   \n...                      ...                                 ...   \n19495                   0.00                               0.000   \n19496                   0.00                               0.000   \n19497                   0.00                               0.000   \n19498                   0.00                               0.000   \n19499                   0.00                               0.000   \n\n       remainder__last_pymnt_amnt  remainder__collections_12_mths_ex_med  \\\n0                        16901.45                                    1.0   \n1                          409.95                                    1.0   \n2                        12074.88                                    0.0   \n3                          238.99                                    0.0   \n4                        20101.30                                    0.0   \n...                           ...                                    ...   \n19495                    26244.05                                    0.0   \n19496                     2978.46                                    0.0   \n19497                     2785.60                                    0.0   \n19498                        3.80                                    0.0   \n19499                     1978.17                                    0.0   \n\n       remainder__acc_now_delinq  remainder__tot_coll_amt  \\\n0                            0.0                      0.0   \n1                            0.0                    273.0   \n2                            0.0                      0.0   \n3                            0.0                      0.0   \n4                            0.0                      0.0   \n...                          ...                      ...   \n19495                        0.0                   4812.0   \n19496                        0.0                      0.0   \n19497                        0.0                      NaN   \n19498                        0.0                      0.0   \n19499                        0.0                      0.0   \n\n       remainder__tot_cur_bal  remainder__total_rev_hi_lim  \n0                     70116.0                      43670.0  \n1                     31306.0                      21600.0  \n2                    196318.0                      68900.0  \n3                      6848.0                      16700.0  \n4                    426287.0                      26100.0  \n...                       ...                          ...  \n19495                110260.0                      20600.0  \n19496                260585.0                      46600.0  \n19497                     NaN                          NaN  \n19498                 88348.0                      48000.0  \n19499                 18342.0                      33400.0  \n\n[19500 rows x 50 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  навчальна  вибірка з числових ознак\n",
        "X_num = df[nums_features]\n",
        "y = (df['y_reg'])\n",
        "X_num.describe()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>annual_inc</th>\n      <th>dti</th>\n      <th>delinq_2yrs</th>\n      <th>inq_last_6mths</th>\n      <th>mths_since_last_delinq</th>\n      <th>open_acc</th>\n      <th>pub_rec</th>\n      <th>...</th>\n      <th>total_rec_int</th>\n      <th>total_rec_late_fee</th>\n      <th>recoveries</th>\n      <th>collection_recovery_fee</th>\n      <th>last_pymnt_amnt</th>\n      <th>collections_12_mths_ex_med</th>\n      <th>acc_now_delinq</th>\n      <th>tot_coll_amt</th>\n      <th>tot_cur_bal</th>\n      <th>total_rev_hi_lim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>1.950000e+04</td>\n      <td>19495.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>9868.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>...</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>19500.000000</td>\n      <td>18630.000000</td>\n      <td>1.863000e+04</td>\n      <td>18630.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14821.008974</td>\n      <td>13.906393</td>\n      <td>448.408998</td>\n      <td>7.580852e+04</td>\n      <td>18.597095</td>\n      <td>0.330769</td>\n      <td>0.664000</td>\n      <td>34.047021</td>\n      <td>11.602462</td>\n      <td>0.225333</td>\n      <td>...</td>\n      <td>2545.939345</td>\n      <td>3.826898</td>\n      <td>298.539651</td>\n      <td>50.258535</td>\n      <td>4140.196449</td>\n      <td>0.018256</td>\n      <td>0.005077</td>\n      <td>222.111541</td>\n      <td>1.361425e+05</td>\n      <td>31819.256200</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8838.026964</td>\n      <td>4.963300</td>\n      <td>265.330204</td>\n      <td>6.233493e+04</td>\n      <td>9.534863</td>\n      <td>0.879724</td>\n      <td>0.942594</td>\n      <td>21.996481</td>\n      <td>5.569023</td>\n      <td>0.628808</td>\n      <td>...</td>\n      <td>2746.267537</td>\n      <td>20.841700</td>\n      <td>1074.575286</td>\n      <td>190.363170</td>\n      <td>6461.795339</td>\n      <td>0.145975</td>\n      <td>0.074594</td>\n      <td>1443.977110</td>\n      <td>1.535275e+05</td>\n      <td>31987.610385</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>500.000000</td>\n      <td>5.310000</td>\n      <td>16.310000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8000.000000</td>\n      <td>10.490000</td>\n      <td>257.880000</td>\n      <td>4.500000e+04</td>\n      <td>12.030000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>8.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>806.397500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>332.712500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.841575e+04</td>\n      <td>13700.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>12775.000000</td>\n      <td>13.350000</td>\n      <td>381.060000</td>\n      <td>6.500000e+04</td>\n      <td>17.980000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>30.000000</td>\n      <td>11.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1650.570000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>749.375000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.321900e+04</td>\n      <td>23500.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>20000.000000</td>\n      <td>16.990000</td>\n      <td>593.490000</td>\n      <td>9.000000e+04</td>\n      <td>24.590000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>50.000000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>3231.047500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5795.580000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.038738e+05</td>\n      <td>39600.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>40000.000000</td>\n      <td>30.990000</td>\n      <td>1546.520000</td>\n      <td>4.260016e+06</td>\n      <td>325.990000</td>\n      <td>16.000000</td>\n      <td>7.000000</td>\n      <td>135.000000</td>\n      <td>75.000000</td>\n      <td>28.000000</td>\n      <td>...</td>\n      <td>26822.380000</td>\n      <td>768.170000</td>\n      <td>26708.310000</td>\n      <td>4807.495800</td>\n      <td>40604.210000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>44169.000000</td>\n      <td>3.078704e+06</td>\n      <td>778500.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 26 columns</p>\n</div>",
            "text/plain": "          loan_amnt      int_rate   installment    annual_inc           dti  \\\ncount  19500.000000  19500.000000  19500.000000  1.950000e+04  19495.000000   \nmean   14821.008974     13.906393    448.408998  7.580852e+04     18.597095   \nstd     8838.026964      4.963300    265.330204  6.233493e+04      9.534863   \nmin      500.000000      5.310000     16.310000  0.000000e+00      0.000000   \n25%     8000.000000     10.490000    257.880000  4.500000e+04     12.030000   \n50%    12775.000000     13.350000    381.060000  6.500000e+04     17.980000   \n75%    20000.000000     16.990000    593.490000  9.000000e+04     24.590000   \nmax    40000.000000     30.990000   1546.520000  4.260016e+06    325.990000   \n\n        delinq_2yrs  inq_last_6mths  mths_since_last_delinq      open_acc  \\\ncount  19500.000000    19500.000000             9868.000000  19500.000000   \nmean       0.330769        0.664000               34.047021     11.602462   \nstd        0.879724        0.942594               21.996481      5.569023   \nmin        0.000000        0.000000                0.000000      0.000000   \n25%        0.000000        0.000000               15.000000      8.000000   \n50%        0.000000        0.000000               30.000000     11.000000   \n75%        0.000000        1.000000               50.000000     14.000000   \nmax       16.000000        7.000000              135.000000     75.000000   \n\n            pub_rec  ...  total_rec_int  total_rec_late_fee    recoveries  \\\ncount  19500.000000  ...   19500.000000        19500.000000  19500.000000   \nmean       0.225333  ...    2545.939345            3.826898    298.539651   \nstd        0.628808  ...    2746.267537           20.841700   1074.575286   \nmin        0.000000  ...       0.000000            0.000000      0.000000   \n25%        0.000000  ...     806.397500            0.000000      0.000000   \n50%        0.000000  ...    1650.570000            0.000000      0.000000   \n75%        0.000000  ...    3231.047500            0.000000      0.000000   \nmax       28.000000  ...   26822.380000          768.170000  26708.310000   \n\n       collection_recovery_fee  last_pymnt_amnt  collections_12_mths_ex_med  \\\ncount             19500.000000     19500.000000                19500.000000   \nmean                 50.258535      4140.196449                    0.018256   \nstd                 190.363170      6461.795339                    0.145975   \nmin                   0.000000         0.000000                    0.000000   \n25%                   0.000000       332.712500                    0.000000   \n50%                   0.000000       749.375000                    0.000000   \n75%                   0.000000      5795.580000                    0.000000   \nmax                4807.495800     40604.210000                    4.000000   \n\n       acc_now_delinq  tot_coll_amt   tot_cur_bal  total_rev_hi_lim  \ncount    19500.000000  18630.000000  1.863000e+04      18630.000000  \nmean         0.005077    222.111541  1.361425e+05      31819.256200  \nstd          0.074594   1443.977110  1.535275e+05      31987.610385  \nmin          0.000000      0.000000  0.000000e+00          0.000000  \n25%          0.000000      0.000000  2.841575e+04      13700.000000  \n50%          0.000000      0.000000  7.321900e+04      23500.000000  \n75%          0.000000      0.000000  2.038738e+05      39600.000000  \nmax          2.000000  44169.000000  3.078704e+06     778500.000000  \n\n[8 rows x 26 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Працюєм з неповними данними\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X_ohe_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(df_ohe))\n",
        "X_ohe_median_strategy = pd.DataFrame(SimpleImputer(strategy='median').fit_transform(df_ohe))\n",
        "X_ohe_mode_strategy = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(df_ohe))\n",
        "X_ohe_constant_strategy = pd.DataFrame(SimpleImputer(strategy='constant').fit_transform(df_ohe))\n",
        "\n",
        "\n",
        "X_num_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X_num))\n",
        "X_num_median_strategy = pd.DataFrame(SimpleImputer(strategy='median').fit_transform(X_num))\n",
        "X_num_mode_strategy = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_num))\n",
        "X_num_constant_strategy = pd.DataFrame(SimpleImputer(strategy='constant').fit_transform(X_num))"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LINEAR MODELS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = mean\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_num_mean_for_train , X_num_mean_for_validation , y_num_for_train , y_num_for_validation = train_test_split(X_num_mean_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_num_mean_for_train = QuantileTransformer().fit_transform(X_num_mean_for_train)\n",
        "X_num_mean_for_validation = QuantileTransformer().fit_transform(X_num_mean_for_validation)\n",
        "\n",
        "\n",
        "pd.DataFrame(X_num_mean_for_train,columns=X_num.columns).describe()\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_num_mean_linear_regression = LinearRegression().fit(X_num_mean_for_train,y_num_for_train)\n",
        "X_num_mean_linear_regression_score = r2_score(y_num_for_validation,X_num_mean_linear_regression.predict(X_num_mean_for_validation))"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = median\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_num_median_for_train , X_num_median_for_validation , y_num_for_train , y_num_for_validation = train_test_split(X_num_median_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_num_median_for_train = QuantileTransformer().fit_transform(X_num_median_for_train)\n",
        "X_num_median_for_validation = QuantileTransformer().fit_transform(X_num_median_for_validation)\n",
        "\n",
        "\n",
        "pd.DataFrame(X_num_median_for_train,columns=X_num.columns).describe()\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_num_median_linear_regression = LinearRegression().fit(X_num_median_for_train,y_num_for_train)\n",
        "X_num_median_linear_regression_score = r2_score(y_num_for_validation,X_num_median_linear_regression.predict(X_num_median_for_validation))"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = most_Frequent\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_num_mode_for_train , X_num_mode_for_validation , y_num_for_train , y_num_for_validation = train_test_split(X_num_mode_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_num_mode_for_train = QuantileTransformer().fit_transform(X_num_mode_for_train)\n",
        "X_num_mode_for_validation = QuantileTransformer().fit_transform(X_num_mode_for_validation)\n",
        "\n",
        "\n",
        "pd.DataFrame(X_num_mode_for_train,columns=X_num.columns).describe()\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_num_mode_linear_regression = LinearRegression().fit(X_num_mode_for_train,y_num_for_train)\n",
        "X_num_mode_linear_regression_score = r2_score(y_num_for_validation,X_num_mode_linear_regression.predict(X_num_mode_for_validation))"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = constant\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_num_constant_for_train , X_num_constant_for_validation , y_num_for_train , y_num_for_validation = train_test_split(X_num_constant_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_num_constant_for_train = QuantileTransformer().fit_transform(X_num_constant_for_train)\n",
        "X_num_constant_for_validation = QuantileTransformer().fit_transform(X_num_constant_for_validation)\n",
        "\n",
        "\n",
        "pd.DataFrame(X_num_constant_for_train,columns=X_num.columns).describe()\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_num_constant_linear_regression = LinearRegression().fit(X_num_constant_for_train,y_num_for_train)\n",
        "X_num_constant_linear_regression_score = r2_score(y_num_for_validation,X_num_constant_linear_regression.predict(X_num_constant_for_validation))"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "####"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = mean\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_ohe_mean_for_train , X_ohe_mean_for_validation , y_ohe_for_train , y_ohe_for_validation = train_test_split(X_ohe_mean_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_ohe_mean_for_train = QuantileTransformer().fit_transform(X_ohe_mean_for_train)\n",
        "X_ohe_mean_for_validation = QuantileTransformer().fit_transform(X_ohe_mean_for_validation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_ohe_mean_linear_regression = LinearRegression().fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "X_ohe_mean_linear_regression_score = r2_score(y_ohe_for_validation,X_ohe_mean_linear_regression.predict(X_ohe_mean_for_validation))"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = mean\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_ohe_median_for_train , X_ohe_median_for_validation , y_ohe_for_train , y_ohe_for_validation = train_test_split(X_ohe_median_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_ohe_median_for_train = QuantileTransformer().fit_transform(X_ohe_median_for_train)\n",
        "X_ohe_median_for_validation = QuantileTransformer().fit_transform(X_ohe_median_for_validation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_ohe_median_linear_regression = LinearRegression().fit(X_ohe_median_for_train,y_ohe_for_train)\n",
        "X_ohe_median_linear_regression_score = r2_score(y_ohe_for_validation,X_ohe_median_linear_regression.predict(X_ohe_median_for_validation))"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = mean\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_ohe_mode_for_train , X_ohe_mode_for_validation , y_ohe_for_train , y_ohe_for_validation = train_test_split(X_ohe_mode_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_ohe_mode_for_train = QuantileTransformer().fit_transform(X_ohe_mode_for_train)\n",
        "X_ohe_mode_for_validation = QuantileTransformer().fit_transform(X_ohe_mode_for_validation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_ohe_mode_linear_regression = LinearRegression().fit(X_ohe_mode_for_train,y_ohe_for_train)\n",
        "X_ohe_mode_linear_regression_score = r2_score(y_ohe_for_validation,X_ohe_mode_linear_regression.predict(X_ohe_mode_for_validation))"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Лінійна регресія по числових ознаках з simple imputer stragegy = mean\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_ohe_constant_for_train , X_ohe_constant_for_validation , y_ohe_for_train , y_ohe_for_validation = train_test_split(X_ohe_constant_strategy,y,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_ohe_constant_for_train = QuantileTransformer().fit_transform(X_ohe_constant_for_train)\n",
        "X_ohe_constant_for_validation = QuantileTransformer().fit_transform(X_ohe_constant_for_validation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LinearRegressions по Вибірці з виключно числових ознак\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_ohe_constant_linear_regression = LinearRegression().fit(X_ohe_constant_for_train,y_ohe_for_train)\n",
        "X_ohe_constant_linear_regression_score = r2_score(y_ohe_for_validation,X_ohe_constant_linear_regression.predict(X_ohe_constant_for_validation))"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LASSO MODELS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Lassoes по Вибірці з виключно числових ознак\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = [0.0001,0.001,0.01,0.1,1,10,100,100]\n",
        "cv = 3\n",
        "\n",
        "Lassoes_X_num_mean = GridSearchCV(\n",
        "    estimator = Lasso(),\n",
        "    param_grid = {'alpha': params,'selection':['cyclic', 'random']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Lassoes_X_num_mean_cv_result = pd.DataFrame(Lassoes_X_num_mean.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "\n",
        "#з Lasso найкращим коефіцієнтом детермінації \n",
        "Lasso_X_num_mean = Lassoes_X_num_mean.best_estimator_\n",
        "\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Lasso_X_num_mean_score = r2_score(y_num_for_validation,(Lasso_X_num_mean.predict(X_num_mean_for_validation)))\n",
        "\n",
        "\n",
        "Lasso_X_num_mean_score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+01, tolerance: 1.701e-01\n  model = cd_fast.enet_coordinate_descent(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e-01, tolerance: 1.719e-01\n  model = cd_fast.enet_coordinate_descent(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "0.696036743905864"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Lassoes по Вибірці з виключно числових ознак\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = [0.0001,0.001,0.01,0.1,1,10,100,100]\n",
        "cv = 3\n",
        "\n",
        "Lassoes_X_num_median = GridSearchCV(\n",
        "    estimator = Lasso(),\n",
        "    param_grid = {'alpha': params,'selection':['cyclic', 'random']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_num_median_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Lassoes_X_num_median_cv_result = pd.DataFrame(Lassoes_X_num_median.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "\n",
        "#з Lasso найкращим коефіцієнтом детермінації \n",
        "Lasso_X_num_median = Lassoes_X_num_median.best_estimator_\n",
        "\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Lasso_X_num_median_score = r2_score(y_num_for_validation,(Lasso_X_num_median.predict(X_num_median_for_validation)))\n",
        "\n",
        "\n",
        "Lasso_X_num_median_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "0.696067714365699"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Lassoes по Вибірці з виключно числових ознак\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = [0.0001,0.001,0.01,0.1,1,10,100,100]\n",
        "cv = 3\n",
        "\n",
        "Lassoes_X_num_mode = GridSearchCV(\n",
        "    estimator = Lasso(),\n",
        "    param_grid = {'alpha': params,'selection':['cyclic', 'random']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_num_mode_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Lassoes_X_num_mode_cv_result = pd.DataFrame(Lassoes_X_num_mode.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "\n",
        "#з Lasso найкращим коефіцієнтом детермінації \n",
        "Lasso_X_num_mode = Lassoes_X_num_mode.best_estimator_\n",
        "\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Lasso_X_num_mode_score = r2_score(y_num_for_validation,(Lasso_X_num_mode.predict(X_num_mode_for_validation)))\n",
        "\n",
        "\n",
        "Lasso_X_num_mode_score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e+00, tolerance: 1.752e-01\n  model = cd_fast.enet_coordinate_descent(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+01, tolerance: 1.719e-01\n  model = cd_fast.enet_coordinate_descent(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "0.6959955182346136"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Lassoes по Вибірці з виключно числових ознак\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = [0.0001,0.001,0.01,0.1,1,10,100,100]\n",
        "cv = 3\n",
        "\n",
        "Lassoes_X_num_constant = GridSearchCV(\n",
        "    estimator = Lasso(),\n",
        "    param_grid = {'alpha': params,'selection':['cyclic', 'random']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_num_constant_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Lassoes_X_num_constant_cv_result = pd.DataFrame(Lassoes_X_num_constant.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "\n",
        "#з Lasso найкращим коефіцієнтом детермінації \n",
        "Lasso_X_num_constant = Lassoes_X_num_constant.best_estimator_\n",
        "\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Lasso_X_num_constant_score = r2_score(y_num_for_validation,(Lasso_X_num_constant.predict(X_num_constant_for_validation)))\n",
        "\n",
        "\n",
        "Lasso_X_num_constant_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "0.6959854110500094"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Lassoes по Вибірці з всіх ознак\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = [0.0001,0.001,0.01,0.1,1,10,100,100]\n",
        "cv = 10\n",
        "\n",
        "Lassoes_X_ohe_mode = GridSearchCV(\n",
        "    estimator = Lasso(),\n",
        "    param_grid = {'alpha': params,'selection':['cyclic', 'random']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_ohe_mode_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Lassoes_X_ohe_mode_cv_result = pd.DataFrame(Lassoes_X_ohe_mode.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "\n",
        "#з Lasso найкращим коефіцієнтом детермінації \n",
        "Lasso_X_ohe_mode = Lassoes_X_ohe_mode.best_estimator_\n",
        "\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Lasso_X_ohe_mode_score = r2_score(y_num_for_validation,(Lasso_X_ohe_mode.predict(X_ohe_mode_for_validation)))\n",
        "\n",
        "\n",
        "Lasso_X_ohe_mode_score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.143e+00, tolerance: 2.334e-01\n  model = cd_fast.enet_coordinate_descent(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+01, tolerance: 2.333e-01\n  model = cd_fast.enet_coordinate_descent(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+01, tolerance: 2.313e-01\n  model = cd_fast.enet_coordinate_descent(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.683e+00, tolerance: 2.329e-01\n  model = cd_fast.enet_coordinate_descent(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "0.6982249841136848"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RIDGE MODELS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridges по Вибірці з виключно числових ознак\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "Ridges_X_num = GridSearchCV(\n",
        "    estimator = Ridge(),\n",
        "    param_grid = {'alpha': params,'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "Ridges_X_num_cv_result = pd.DataFrame(Ridges_X_num.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "#з Ridge найкращим коефіцієнтом детермінації \n",
        "Ridge_X_num = Ridges_X_num.best_estimator_\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Ridge_X_num_score = r2_score(y_num_for_validation,(Ridge_X_num.predict(X_num_mean_for_validation)))\n",
        "\n",
        "\n",
        "Ridge_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n80 fits failed out of a total of 640.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1175, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 852, in fit\n    raise ValueError(\nValueError: 'lbfgs' solver can be used only when positive=True. Please use another solver.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.68545674 0.68545674 0.68545674 0.68545746 0.68545683 0.6854569\n 0.68545695        nan 0.68545685 0.68545685 0.68545685 0.68545756\n 0.68545669 0.68545758 0.68545706        nan 0.68545784 0.68545784\n 0.68545784 0.68545855 0.68545769 0.68545787 0.68545801        nan\n 0.6854642  0.6854642  0.6854642  0.6854648  0.68546374 0.6854647\n 0.68546426        nan 0.68544246 0.68544246 0.68544246 0.68542206\n 0.68544212 0.6854417  0.68544227        nan 0.68499223 0.68499223\n 0.68499223 0.68498877 0.6849933  0.6849923  0.68499186        nan\n 0.68025935 0.68025935 0.68025935 0.68025888 0.68025882 0.6802595\n 0.68025939        nan 0.68025935 0.68025935 0.68025935 0.68025888\n 0.68025882 0.68025896 0.68025988        nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "0.6959963773395834"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridges по Вибірці з всіх ознак\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "Ridges_X_ohe = GridSearchCV(\n",
        "    estimator = Ridge(),\n",
        "    param_grid = {'alpha': params,'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']},\n",
        "    cv = cv,\n",
        "    n_jobs = -1,\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "Ridges_X_ohe_cv_result = pd.DataFrame(Ridges_X_ohe.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "#з Ridge найкращим коефіцієнтом детермінації \n",
        "Ridge_X_ohe = Ridges_X_ohe.best_estimator_\n",
        "\n",
        "# Коефіцієне детермінації моделі з найкращим mean_test_score на відкладеній вибірці\n",
        "Ridge_X_ohe_score = r2_score(y_ohe_for_validation,(Ridge_X_ohe.predict(X_ohe_mean_for_validation)))\n",
        "\n",
        "\n",
        "Ridge_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n80 fits failed out of a total of 640.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1175, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 852, in fit\n    raise ValueError(\nValueError: 'lbfgs' solver can be used only when positive=True. Please use another solver.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.68849813 0.68849813 0.68849813 0.68849096 0.6884899  0.68849822\n 0.68849852        nan 0.68849829 0.68849829 0.68849829 0.6884911\n 0.68849194 0.68849827 0.68849869        nan 0.6884998  0.6884998\n 0.6884998  0.68849247 0.68849169 0.68849989 0.68850015        nan\n 0.68850903 0.68850903 0.68850903 0.68851574 0.68850218 0.68850903\n 0.68850911        nan 0.68846664 0.68846664 0.68846664 0.68846632\n 0.68846098 0.68846552 0.68846624        nan 0.68787109 0.68787109\n 0.68787109 0.68786306 0.68787107 0.68787079 0.68787122        nan\n 0.68222157 0.68222157 0.68222157 0.68222009 0.68222099 0.68222154\n 0.68222131        nan 0.68222157 0.68222157 0.68222157 0.68222009\n 0.68222099 0.68222159 0.6822215         nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "0.6980748400840455"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  SVM Regressor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "\n",
        "SVR_X_num = GridSearchCV(\n",
        "    estimator = SVR(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "SVR_X_num_cv_results = pd.DataFrame(SVR_X_num.cv_results_)\n",
        "\n",
        "SVR_X_num = SVR_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVR_X_num_score = r2_score(y_ohe_for_validation,SVR_X_num.predict(X_num_median_for_validation))\n",
        "\n",
        "\n",
        "SVR_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "0.6733576913658925"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "\n",
        "SVR_X_ohe = GridSearchCV(\n",
        "    estimator = SVR(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "SVR_X_ohe_cv_results = pd.DataFrame(SVR_X_ohe.cv_results_)\n",
        "\n",
        "SVR_X_ohe = SVR_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVR_X_ohe_score = r2_score(y_ohe_for_validation,SVR_X_ohe.predict(X_ohe_median_for_validation))\n",
        "\n",
        "\n",
        "SVR_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "0.6819577583276215"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Regressor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "KNR_X_num = GridSearchCV(\n",
        "    estimator = KNeighborsRegressor(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "KNR_X_num_cv_results = pd.DataFrame(KNR_X_num.cv_results_)\n",
        "\n",
        "KNR_X_num = KNR_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNR_X_num_score = r2_score(y_num_for_validation,KNR_X_num.predict(X_num_mean_for_validation))\n",
        "\n",
        "\n",
        "KNR_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "0.6556133268406088"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "KNR_X_ohe = GridSearchCV(\n",
        "    estimator = KNeighborsRegressor(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "KNR_X_ohe_cv_results = pd.DataFrame(KNR_X_ohe.cv_results_)\n",
        "\n",
        "KNR_X_ohe = KNR_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNR_X_ohe_score = r2_score(y_ohe_for_validation,KNR_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "\n",
        "\n",
        "KNR_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "0.5907285286242656"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.tree.DecisionTreeRegressor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "DTR_X_num = GridSearchCV(\n",
        "    estimator = DecisionTreeRegressor(),\n",
        "    param_grid= {'max_features':['sqrt', 'log2'],'splitter':['random','best']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "DTR_X_num_cv_results = pd.DataFrame(DTR_X_num.cv_results_)\n",
        "\n",
        "DTR_X_num = DTR_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTR_X_num_score = r2_score(y_num_for_validation,DTR_X_num.predict(X_num_mean_for_validation))\n",
        "DTR_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "0.47603320714409136"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "DTR_X_ohe = GridSearchCV(\n",
        "    estimator = DecisionTreeRegressor(),\n",
        "    param_grid= {'max_features':['sqrt', 'log2'],'splitter':['random','best']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "DTR_X_ohe_cv_results = pd.DataFrame(DTR_X_ohe.cv_results_)\n",
        "\n",
        "DTR_X_ohe = DTR_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTR_X_ohe_score = r2_score(y_ohe_for_validation,DTR_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "DTR_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "0.4265523632993513"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.ensemble.RandomForestRegressor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "RFR_X_num = GridSearchCV(\n",
        "    estimator = RandomForestRegressor(),\n",
        "    param_grid= {'criterion':['squared_error', 'absolute_error','friedman_mse','poisson'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "RFR_X_num_cv_results = pd.DataFrame(RFR_X_num.cv_results_)\n",
        "\n",
        "RFR_X_num = RFR_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFR_X_num_score = r2_score(y_num_for_validation,DTR_X_num.predict(X_num_mean_for_validation))\n",
        "RFR_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "0.47603320714409136"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "RFR_X_ohe = GridSearchCV(\n",
        "    estimator = RandomForestRegressor(),\n",
        "    param_grid= {'criterion':['squared_error', 'absolute_error','friedman_mse','poisson'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "RFR_X_ohe_cv_results = pd.DataFrame(RFR_X_ohe.cv_results_)\n",
        "\n",
        "RFR_X_ohe = RFR_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFR_X_ohe_score = r2_score(y_ohe_for_validation,DTR_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "RFR_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "0.4265523632993513"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Models_num = [X_num_mean_linear_regression,X_num_median_linear_regression,X_num_mode_linear_regression,X_num_constant_linear_regression,Lasso_X_num_mean,Lasso_X_num_median,Lasso_X_num_mode,Lasso_X_num_constant,Ridge_X_num,SVR_X_num,KNR_X_num,DTR_X_num,RFR_X_num]\n",
        "Models_ohe = [X_ohe_mean_linear_regression,X_ohe_median_linear_regression,X_ohe_mode_linear_regression,X_ohe_constant_linear_regression,Lasso_X_ohe_mode,Ridge_X_ohe,SVR_X_ohe,KNR_X_ohe,DTR_X_ohe,RFR_X_ohe]\n",
        "Models = pd.DataFrame(data = {'Model_Name': ['X_num_mean_linear_regression','X_num_median_linear_regression','X_num_mode_linear_regression','X_num_constant_linear_regression','Lasso_X_num_mean','Lasso_X_num_median','Lasso_X_num_mode','Lasso_X_num_constant','Lasso_X_ohe_mode','Ridge_X_num','Ridge_X_ohe','SVR_X_num','SVR_X_ohe','KNR_X_num','KNR_X_ohe','DTR_X_num','DTR_X_ohe','RFR_X_num','RFR_X_ohe'],'Model':[X_num_mean_linear_regression,X_num_median_linear_regression,X_num_mode_linear_regression,X_num_constant_linear_regression,Lasso_X_num_mean,Lasso_X_num_median,Lasso_X_num_mode,Lasso_X_num_constant,Lasso_X_ohe_mode,Ridge_X_num,Ridge_X_ohe,SVR_X_num,SVR_X_ohe,KNR_X_num,KNR_X_ohe,DTR_X_num,DTR_X_ohe,RFR_X_num,RFR_X_ohe],'r2_score_on_X_for_validation':[X_num_mean_linear_regression_score,X_num_median_linear_regression_score,X_num_mode_linear_regression_score,X_num_constant_linear_regression_score,Lasso_X_num_mean_score,Lasso_X_num_median_score,Lasso_X_num_mode_score,Lasso_X_num_constant_score,Lasso_X_ohe_mode_score,Ridge_X_num_score,Ridge_X_ohe_score,SVR_X_num_score,SVR_X_ohe_score,KNR_X_num_score,KNR_X_ohe_score,DTR_X_num_score,DTR_X_ohe_score,RFR_X_num_score,RFR_X_ohe_score]})\n",
        "optimal_model = Models[Models['r2_score_on_X_for_validation'] == Models['r2_score_on_X_for_validation'].values.max()]['Model'].values[0]\n",
        "Models"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_Name</th>\n      <th>Model</th>\n      <th>r2_score_on_X_for_validation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>X_num_mean_linear_regression</td>\n      <td>LinearRegression()</td>\n      <td>0.695997</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>X_num_median_linear_regression</td>\n      <td>LinearRegression()</td>\n      <td>0.696073</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>X_num_mode_linear_regression</td>\n      <td>LinearRegression()</td>\n      <td>0.696012</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>X_num_constant_linear_regression</td>\n      <td>LinearRegression()</td>\n      <td>0.695988</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lasso_X_num_mean</td>\n      <td>Lasso(alpha=0.0001)</td>\n      <td>0.696037</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Lasso_X_num_median</td>\n      <td>Lasso(alpha=0.0001, selection='random')</td>\n      <td>0.696068</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Lasso_X_num_mode</td>\n      <td>Lasso(alpha=0.0001)</td>\n      <td>0.695996</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Lasso_X_num_constant</td>\n      <td>Lasso(alpha=0.0001)</td>\n      <td>0.695985</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Lasso_X_ohe_mode</td>\n      <td>Lasso(alpha=0.0001)</td>\n      <td>0.698225</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Ridge_X_num</td>\n      <td>Ridge(alpha=0.1, solver='lsqr')</td>\n      <td>0.695996</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Ridge_X_ohe</td>\n      <td>Ridge(alpha=0.1, solver='lsqr')</td>\n      <td>0.698075</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>SVR_X_num</td>\n      <td>SVR()</td>\n      <td>0.673358</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVR_X_ohe</td>\n      <td>SVR()</td>\n      <td>0.681958</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNR_X_num</td>\n      <td>KNeighborsRegressor(algorithm='ball_tree')</td>\n      <td>0.655613</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>KNR_X_ohe</td>\n      <td>KNeighborsRegressor(weights='distance')</td>\n      <td>0.590729</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DTR_X_num</td>\n      <td>DecisionTreeRegressor(max_features='sqrt')</td>\n      <td>0.476033</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DTR_X_ohe</td>\n      <td>DecisionTreeRegressor(max_features='sqrt')</td>\n      <td>0.426552</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>RFR_X_num</td>\n      <td>(DecisionTreeRegressor(criterion='poisson', ma...</td>\n      <td>0.476033</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>RFR_X_ohe</td>\n      <td>(DecisionTreeRegressor(max_features='sqrt', ra...</td>\n      <td>0.426552</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                          Model_Name  \\\n0       X_num_mean_linear_regression   \n1     X_num_median_linear_regression   \n2       X_num_mode_linear_regression   \n3   X_num_constant_linear_regression   \n4                   Lasso_X_num_mean   \n5                 Lasso_X_num_median   \n6                   Lasso_X_num_mode   \n7               Lasso_X_num_constant   \n8                   Lasso_X_ohe_mode   \n9                        Ridge_X_num   \n10                       Ridge_X_ohe   \n11                         SVR_X_num   \n12                         SVR_X_ohe   \n13                         KNR_X_num   \n14                         KNR_X_ohe   \n15                         DTR_X_num   \n16                         DTR_X_ohe   \n17                         RFR_X_num   \n18                         RFR_X_ohe   \n\n                                                Model  \\\n0                                  LinearRegression()   \n1                                  LinearRegression()   \n2                                  LinearRegression()   \n3                                  LinearRegression()   \n4                                 Lasso(alpha=0.0001)   \n5             Lasso(alpha=0.0001, selection='random')   \n6                                 Lasso(alpha=0.0001)   \n7                                 Lasso(alpha=0.0001)   \n8                                 Lasso(alpha=0.0001)   \n9                     Ridge(alpha=0.1, solver='lsqr')   \n10                    Ridge(alpha=0.1, solver='lsqr')   \n11                                              SVR()   \n12                                              SVR()   \n13         KNeighborsRegressor(algorithm='ball_tree')   \n14            KNeighborsRegressor(weights='distance')   \n15         DecisionTreeRegressor(max_features='sqrt')   \n16         DecisionTreeRegressor(max_features='sqrt')   \n17  (DecisionTreeRegressor(criterion='poisson', ma...   \n18  (DecisionTreeRegressor(max_features='sqrt', ra...   \n\n    r2_score_on_X_for_validation  \n0                       0.695997  \n1                       0.696073  \n2                       0.696012  \n3                       0.695988  \n4                       0.696037  \n5                       0.696068  \n6                       0.695996  \n7                       0.695985  \n8                       0.698225  \n9                       0.695996  \n10                      0.698075  \n11                      0.673358  \n12                      0.681958  \n13                      0.655613  \n14                      0.590729  \n15                      0.476033  \n16                      0.426552  \n17                      0.476033  \n18                      0.426552  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.0001)</pre></div> </div></div></div></div>",
            "text/plain": "Lasso(alpha=0.0001)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпортуємо DataFrame для зовнішнього оцінювання\n",
        "test = pd.read_csv('predict.csv')\n",
        "\n",
        "\n",
        "# Функція яка приведе зовнішній датасет до вигляду, який приймає рішаюча модель\n",
        "def transform_test_data(model,test):\n",
        "    \n",
        "    \n",
        "    if model in Models_num:\n",
        "        test_X_num_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(test[nums_features]))\n",
        "        test = QuantileTransformer().fit_transform(test_X_num_mean_strategy)\n",
        "        prediction = model.predict(test)\n",
        "        return prediction\n",
        "    \n",
        "    \n",
        "    else:\n",
        "        from sklearn.compose import make_column_transformer\n",
        "        from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
        "\n",
        "        text_features_test = [i for i in test.columns if type(test[i][0]) == str]\n",
        "        nums_features_test = [i for i in test.columns if i not in text_features]\n",
        "        columns_ohe_test = make_column_transformer(\n",
        "            ( OneHotEncoder(handle_unknown='ignore',sparse_output=False) ,text_features_test),\n",
        "            remainder = 'passthrough'\n",
        "        ).set_output(transform='pandas')\n",
        "        test = columns_ohe_test.fit_transform(test)\n",
        "        test = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(test))\n",
        "        test = QuantileTransformer().fit_transform(test)\n",
        "        prediction = model.predict(test)\n",
        "        return prediction\n",
        "\n",
        "\n",
        "best_reg_model_predictions =  transform_test_data(optimal_model,test)\n",
        "\n",
        "\n",
        "\n",
        "pd.Series(best_reg_model_predictions).to_csv('predictions_reg.csv')\n"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Висновок задача регресіі\n",
        " Модель(з відповідними парамптрами) збережена у змінну optimal модель , має найкращий R2-score на відкладеній вибірці, а одже і є найкращою моделлю для вирішення задачі регресії."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 6"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regressions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "cv = 3\n",
        "LogisticRegression = GridSearchCV(\n",
        "    estimator= LogisticRegression(),\n",
        "    param_grid= {'penalty': ['l1','l2','elasticnet'] , 'C' : np.logspace(-4,4,5), 'solver' : ['saga'],'max_iter' : [100,1000,2500,3000]},\n",
        "    cv = cv,\n",
        "    n_jobs= -1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "LogisticRegression_X_num = pd.DataFrame(LogisticRegression.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "LogisticRegression_num_best_model = LogisticRegression.best_estimator_\n",
        "print(f'Accuracy для найкращої моделі з на відкладеній вибірці: {accuracy_score(y_num_for_validation,LogisticRegression_num_best_model.predict(X_num_mean_for_validation))}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n60 fits failed out of a total of 180.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\nValueError: l1_ratio must be specified when penalty is elasticnet.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.74608059 0.74608059        nan 0.74608059 0.74608059        nan\n 0.74608059 0.74608059        nan 0.74608059 0.74608059        nan\n 0.91831502 0.9170696         nan 0.91831502 0.9170696         nan\n 0.91831502 0.9170696         nan 0.91831502 0.9170696         nan\n 0.91428571 0.91472527        nan 0.91428571 0.91472527        nan\n 0.91428571 0.91472527        nan 0.91428571 0.91472527        nan\n 0.91494505 0.91479853        nan 0.91472527 0.91472527        nan\n 0.91472527 0.91472527        nan 0.91472527 0.91472527        nan\n 0.91494505 0.91494505        nan 0.91472527 0.91472527        nan\n 0.91465201 0.91465201        nan 0.91465201 0.91465201        nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy для найкращої моделі з на відкладеній вибірці: 0.9196581196581196\n"
        }
      ],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "cv = 3\n",
        "LogisticRegression_ohe = GridSearchCV(\n",
        "    estimator= LogisticRegression(),\n",
        "    param_grid= {'penalty': ['l1','l2','elasticnet'] , 'C' : np.logspace(-4,4,5), 'solver' : ['saga'],'max_iter' : [100,1000,2500,3000]},\n",
        "    cv = cv,\n",
        "    n_jobs= -1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "LogisticRegression_X_ohe = pd.DataFrame(LogisticRegression_ohe.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "LogisticRegression_ohe_best_model = LogisticRegression_ohe.best_estimator_\n",
        "print(f'Accuracy для найкращої моделі з на відкладеній вибірці: {accuracy_score(y_ohe_for_validation,LogisticRegression_ohe_best_model.predict(X_ohe_mean_for_validation))}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n60 fits failed out of a total of 180.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\nValueError: l1_ratio must be specified when penalty is elasticnet.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.74608059 0.74608059        nan 0.74608059 0.74608059        nan\n 0.74608059 0.74608059        nan 0.74608059 0.74608059        nan\n 0.91831502 0.91677656        nan 0.91831502 0.91677656        nan\n 0.91831502 0.91677656        nan 0.91831502 0.91677656        nan\n 0.91802198 0.91758242        nan 0.91794872 0.91758242        nan\n 0.91794872 0.91758242        nan 0.91794872 0.91758242        nan\n 0.91802198 0.9181685         nan 0.9181685  0.91824176        nan\n 0.9181685  0.91824176        nan 0.91824176 0.91824176        nan\n 0.91809524 0.91809524        nan 0.91809524 0.91809524        nan\n 0.91802198 0.91802198        nan 0.91809524 0.91809524        nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy для найкращої моделі з на відкладеній вибірці: 0.9196581196581196\n"
        }
      ],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "SVC_X_num = GridSearchCV(\n",
        "    estimator = SVC(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "SVC_X_num_cv_results = pd.DataFrame(SVC_X_num.cv_results_)\n",
        "\n",
        "SVC_X_num = SVC_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVC_X_num_score = accuracy_score(y_num_for_validation,SVC_X_num.predict(X_num_median_for_validation))\n",
        "\n",
        "\n",
        "SVC_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "0.9188034188034188"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "SVC_X_ohe = GridSearchCV(\n",
        "    estimator = SVC(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "SVC_X_ohe_cv_results = pd.DataFrame(SVC_X_ohe.cv_results_)\n",
        "\n",
        "SVC_X_ohe = SVC_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVC_X_ohe_score = accuracy_score(y_ohe_for_validation,SVC_X_ohe.predict(X_ohe_median_for_validation))\n",
        "\n",
        "\n",
        "SVC_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "0.9218803418803418"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "KNC_X_ohe = GridSearchCV(\n",
        "    estimator = KNeighborsClassifier(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "KNC_X_ohe_cv_results = pd.DataFrame(KNC_X_ohe.cv_results_)\n",
        "\n",
        "KNC_X_ohe = KNC_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNC_X_ohe_score = accuracy_score(y_ohe_for_validation,KNC_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "\n",
        "\n",
        "KNC_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "0.9025641025641026"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "KNC_X_num = GridSearchCV(\n",
        "    estimator = KNeighborsClassifier(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "KNC_X_num_cv_results = pd.DataFrame(KNC_X_num.cv_results_)\n",
        "\n",
        "KNC_X_num = KNC_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNC_X_num_score = accuracy_score(y_num_for_validation,KNC_X_num.predict(X_num_mean_for_validation))\n",
        "\n",
        "\n",
        "KNC_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "0.9092307692307692"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DTC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "DTC_X_ohe = GridSearchCV(\n",
        "    estimator = DecisionTreeClassifier(),\n",
        "    param_grid= {'splitter':['gini', 'entropy','log_loss'],'splitter':['best','random'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "DTC_X_ohe_cv_results = pd.DataFrame(DTC_X_ohe.cv_results_)\n",
        "\n",
        "DTC_X_ohe = DTC_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTC_X_ohe_score = accuracy_score(y_ohe_for_validation,DTC_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "DTC_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "0.8941880341880342"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "DTC_X_num = GridSearchCV(\n",
        "    estimator = DecisionTreeClassifier(),\n",
        "    param_grid= {'splitter':['gini', 'entropy','log_loss'],'splitter':['best','random'],'max_features':['sqrt','log2']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "DTC_X_num_cv_results = pd.DataFrame(DTC_X_num.cv_results_)\n",
        "\n",
        "DTC_X_num = DTC_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTC_X_num_score = accuracy_score(y_num_for_validation,DTC_X_num.predict(X_num_mean_for_validation))\n",
        "DTC_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "0.8984615384615384"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn.ensemble.RandomForestClassifier"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "RFC_X_num = GridSearchCV(\n",
        "    estimator = RandomForestClassifier(),\n",
        "    param_grid= {'criterion':['gini', 'entropy','log_loss'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mean_for_train,y_num_for_train)\n",
        "\n",
        "\n",
        "RFC_X_num_cv_results = pd.DataFrame(RFC_X_num.cv_results_)\n",
        "\n",
        "RFC_X_num = RFC_X_num.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFC_X_num_score = accuracy_score(y_num_for_validation,RFC_X_num.predict(X_num_mean_for_validation))\n",
        "RFC_X_num_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "0.9206837606837607"
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "RFC_X_ohe = GridSearchCV(\n",
        "    estimator = RandomForestClassifier(),\n",
        "    param_grid= {'criterion':['gini', 'entropy','log_loss'],'max_features':['sqrt','log2']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mean_for_train,y_ohe_for_train)\n",
        "\n",
        "\n",
        "RFC_X_ohe_cv_results = pd.DataFrame(RFC_X_ohe.cv_results_)\n",
        "\n",
        "RFC_X_ohe = RFC_X_ohe.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFC_X_ohe_score = accuracy_score(y_ohe_for_validation,RFC_X_ohe.predict(X_ohe_mean_for_validation))\n",
        "RFC_X_ohe_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "0.9225641025641026"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Models_task_6 = pd.DataFrame(data = {'Model_Name': ['LogisticRegression_num_best_model','LogisticRegression_ohe_best_model','SVC_X_num','SVC_X_ohe','KNC_X_num','KNC_X_ohe','DTC_X_num','DTC_X_ohe','RFC_X_num','RFC_X_ohe'],'Model':[LogisticRegression_num_best_model,LogisticRegression_ohe_best_model,SVC_X_num,SVC_X_ohe,KNC_X_num,KNC_X_ohe,DTC_X_num,DTC_X_ohe,RFC_X_num,RFC_X_ohe],'Accuracy':[accuracy_score(y_num_for_validation,LogisticRegression_num_best_model.predict(X_num_mean_for_validation)),accuracy_score(y_ohe_for_validation,LogisticRegression_ohe_best_model.predict(X_ohe_mean_for_validation)),SVC_X_num_score,SVC_X_ohe_score,KNC_X_num_score,KNC_X_ohe_score,DTC_X_num_score,DTC_X_ohe_score,RFC_X_num_score,RFC_X_ohe_score]})\n",
        "Models_task_6"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_Name</th>\n      <th>Model</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression_num_best_model</td>\n      <td>LogisticRegression(C=0.01, penalty='l1', solve...</td>\n      <td>0.919658</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LogisticRegression_ohe_best_model</td>\n      <td>LogisticRegression(C=0.01, penalty='l1', solve...</td>\n      <td>0.919658</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC_X_num</td>\n      <td>SVC(kernel='poly')</td>\n      <td>0.918803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC_X_ohe</td>\n      <td>SVC(kernel='poly')</td>\n      <td>0.921880</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNC_X_num</td>\n      <td>KNeighborsClassifier(algorithm='ball_tree', we...</td>\n      <td>0.909231</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNC_X_ohe</td>\n      <td>KNeighborsClassifier(algorithm='ball_tree', we...</td>\n      <td>0.902564</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DTC_X_num</td>\n      <td>DecisionTreeClassifier(max_features='sqrt')</td>\n      <td>0.898462</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DTC_X_ohe</td>\n      <td>DecisionTreeClassifier(max_features='sqrt')</td>\n      <td>0.894188</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RFC_X_num</td>\n      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n      <td>0.920684</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RFC_X_ohe</td>\n      <td>(DecisionTreeClassifier(criterion='log_loss', ...</td>\n      <td>0.922564</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                          Model_Name  \\\n0  LogisticRegression_num_best_model   \n1  LogisticRegression_ohe_best_model   \n2                          SVC_X_num   \n3                          SVC_X_ohe   \n4                          KNC_X_num   \n5                          KNC_X_ohe   \n6                          DTC_X_num   \n7                          DTC_X_ohe   \n8                          RFC_X_num   \n9                          RFC_X_ohe   \n\n                                               Model  Accuracy  \n0  LogisticRegression(C=0.01, penalty='l1', solve...  0.919658  \n1  LogisticRegression(C=0.01, penalty='l1', solve...  0.919658  \n2                                 SVC(kernel='poly')  0.918803  \n3                                 SVC(kernel='poly')  0.921880  \n4  KNeighborsClassifier(algorithm='ball_tree', we...  0.909231  \n5  KNeighborsClassifier(algorithm='ball_tree', we...  0.902564  \n6        DecisionTreeClassifier(max_features='sqrt')  0.898462  \n7        DecisionTreeClassifier(max_features='sqrt')  0.894188  \n8  (DecisionTreeClassifier(criterion='entropy', m...  0.920684  \n9  (DecisionTreeClassifier(criterion='log_loss', ...  0.922564  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "def heigher_accurace_model(model_num,model_ohe):\n",
        "    if accuracy_score(y_num_for_validation,model_num.predict(X_num_mean_for_validation)) >= accuracy_score(y_ohe_for_validation,model_ohe.predict(X_ohe_mean_for_validation)):\n",
        "        return [y_num_for_validation,X_num_mean_for_validation,model_num]\n",
        "    else:\n",
        "        return [y_ohe_for_validation,X_ohe_mean_for_validation,model_ohe]\n",
        "\n",
        "k = heigher_accurace_model(SVC_X_num,SVC_X_ohe)\n",
        "\n",
        "        "
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = heigher_accurace_model(LogisticRegression_num_best_model,LogisticRegression_ohe_best_model)\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rep = classification_report(model[0],model[2].predict(model[1]))\n",
        "print(rep)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.90      1.00      0.95      4316\n           1       1.00      0.69      0.82      1534\n\n    accuracy                           0.92      5850\n   macro avg       0.95      0.85      0.88      5850\nweighted avg       0.93      0.92      0.91      5850\n\n"
        }
      ],
      "execution_count": 54,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(model[0], model[2].decision_function(model[1]))\n",
        "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x138554850>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(model[0], model[2].decision_function(model[1]))\n",
        "PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x141004d90>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC Metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = heigher_accurace_model(SVC_X_num,SVC_X_ohe)\n",
        "from sklearn.metrics import classification_report\n",
        "rep = classification_report(model[0],model[2].predict(model[1]))\n",
        "print(rep)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.99      0.95      4316\n           1       0.98      0.72      0.83      1534\n\n    accuracy                           0.92      5850\n   macro avg       0.94      0.86      0.89      5850\nweighted avg       0.93      0.92      0.92      5850\n\n"
        }
      ],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(model[0], model[2].decision_function(model[1]))\n",
        "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x138a10990>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(model[0], model[2].decision_function(model[1]))\n",
        "PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x140fafa50>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNC Metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = heigher_accurace_model(KNC_X_num,KNC_X_ohe)\n",
        "from sklearn.metrics import classification_report\n",
        "rep = classification_report(model[0],model[2].predict(model[1]))\n",
        "print(rep)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94      4316\n           1       0.90      0.74      0.81      1534\n\n    accuracy                           0.91      5850\n   macro avg       0.91      0.85      0.88      5850\nweighted avg       0.91      0.91      0.91      5850\n\n"
        }
      ],
      "execution_count": 60,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x138a9e110>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x14106df90>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DTC Metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = heigher_accurace_model(DTC_X_num,DTC_X_ohe)\n",
        "from sklearn.metrics import classification_report\n",
        "rep = classification_report(model[0],model[2].predict(model[1]))\n",
        "print(rep)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93      4316\n           1       0.81      0.80      0.81      1534\n\n    accuracy                           0.90      5850\n   macro avg       0.87      0.87      0.87      5850\nweighted avg       0.90      0.90      0.90      5850\n\n"
        }
      ],
      "execution_count": 63,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1410c7ad0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x1411712d0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 65,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RFC Metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = heigher_accurace_model(RFC_X_num,RFC_X_ohe)\n",
        "from sklearn.metrics import classification_report\n",
        "rep = classification_report(model[0],model[2].predict(model[1]))\n",
        "print(rep)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.92      0.99      0.95      4316\n           1       0.95      0.74      0.83      1534\n\n    accuracy                           0.92      5850\n   macro avg       0.93      0.86      0.89      5850\nweighted avg       0.92      0.92      0.92      5850\n\n"
        }
      ],
      "execution_count": 66,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1410edc90>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(model[0], model[2].predict_proba(model[1])[:,1])\n",
        "PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x14116c6d0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 68,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_task6_num = [LogisticRegression_num_best_model,SVC_X_num,KNC_X_num,DTC_X_num,RFC_X_num]\n",
        "optimal_model_task_6 = Models_task_6[Models_task_6['Accuracy'] == Models_task_6['Accuracy'].values.max()]['Model'].values[0]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Висновок задача двокласової красифікації\n",
        " Модель(з відповідними парамптрами) збережена у змінну optimal_model_task_6 модель , має найкращий accuracy-score на відкладеній вибірці, а одже і є найкращою моделлю для вирішення двокласової красифікаціїю"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 4"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_csv('data.csv')"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "ds['loan_status'] = label_encoder.fit_transform(ds['loan_status'])\n"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ds_ohe = columns_ohe.fit_transform(ds)\n",
        "ds_ohe = ds_ohe.drop(columns=['onehotencoder__loan_status_0','onehotencoder__home_ownership_ANY','onehotencoder__home_ownership_OTHER',\n",
        "       'onehotencoder__loan_status_1', 'onehotencoder__loan_status_2',\n",
        "       'onehotencoder__loan_status_3', 'onehotencoder__loan_status_4'])\n",
        "\n",
        "ds_ohe"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>onehotencoder__grade_A</th>\n      <th>onehotencoder__grade_B</th>\n      <th>onehotencoder__grade_C</th>\n      <th>onehotencoder__grade_D</th>\n      <th>onehotencoder__grade_E</th>\n      <th>onehotencoder__grade_F</th>\n      <th>onehotencoder__grade_G</th>\n      <th>onehotencoder__emp_length_1 year</th>\n      <th>onehotencoder__emp_length_10+ years</th>\n      <th>onehotencoder__emp_length_2 years</th>\n      <th>...</th>\n      <th>remainder__total_rec_int</th>\n      <th>remainder__total_rec_late_fee</th>\n      <th>remainder__recoveries</th>\n      <th>remainder__collection_recovery_fee</th>\n      <th>remainder__last_pymnt_amnt</th>\n      <th>remainder__collections_12_mths_ex_med</th>\n      <th>remainder__acc_now_delinq</th>\n      <th>remainder__tot_coll_amt</th>\n      <th>remainder__tot_cur_bal</th>\n      <th>remainder__total_rev_hi_lim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3359.33</td>\n      <td>78.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>16901.45</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>70116.0</td>\n      <td>43670.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5302.70</td>\n      <td>0.0</td>\n      <td>1614.60</td>\n      <td>145.314</td>\n      <td>409.95</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>273.0</td>\n      <td>31306.0</td>\n      <td>21600.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2148.75</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>12074.88</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>196318.0</td>\n      <td>68900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2109.37</td>\n      <td>15.0</td>\n      <td>127.05</td>\n      <td>22.869</td>\n      <td>238.99</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6848.0</td>\n      <td>16700.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>88.83</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>20101.30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426287.0</td>\n      <td>26100.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19495</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>223.71</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>26244.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4812.0</td>\n      <td>110260.0</td>\n      <td>20600.0</td>\n    </tr>\n    <tr>\n      <th>19496</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>77.05</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2978.46</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>260585.0</td>\n      <td>46600.0</td>\n    </tr>\n    <tr>\n      <th>19497</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3020.67</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>2785.60</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19498</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3909.77</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>3.80</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>88348.0</td>\n      <td>48000.0</td>\n    </tr>\n    <tr>\n      <th>19499</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>43.26</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>1978.17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18342.0</td>\n      <td>33400.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19500 rows × 50 columns</p>\n</div>",
            "text/plain": "       onehotencoder__grade_A  onehotencoder__grade_B  onehotencoder__grade_C  \\\n0                         0.0                     1.0                     0.0   \n1                         0.0                     0.0                     0.0   \n2                         1.0                     0.0                     0.0   \n3                         0.0                     0.0                     0.0   \n4                         0.0                     1.0                     0.0   \n...                       ...                     ...                     ...   \n19495                     0.0                     0.0                     1.0   \n19496                     0.0                     0.0                     1.0   \n19497                     0.0                     1.0                     0.0   \n19498                     0.0                     1.0                     0.0   \n19499                     0.0                     0.0                     1.0   \n\n       onehotencoder__grade_D  onehotencoder__grade_E  onehotencoder__grade_F  \\\n0                         0.0                     0.0                     0.0   \n1                         1.0                     0.0                     0.0   \n2                         0.0                     0.0                     0.0   \n3                         1.0                     0.0                     0.0   \n4                         0.0                     0.0                     0.0   \n...                       ...                     ...                     ...   \n19495                     0.0                     0.0                     0.0   \n19496                     0.0                     0.0                     0.0   \n19497                     0.0                     0.0                     0.0   \n19498                     0.0                     0.0                     0.0   \n19499                     0.0                     0.0                     0.0   \n\n       onehotencoder__grade_G  onehotencoder__emp_length_1 year  \\\n0                         0.0                               0.0   \n1                         0.0                               0.0   \n2                         0.0                               0.0   \n3                         0.0                               0.0   \n4                         0.0                               0.0   \n...                       ...                               ...   \n19495                     0.0                               0.0   \n19496                     0.0                               0.0   \n19497                     0.0                               0.0   \n19498                     0.0                               0.0   \n19499                     0.0                               0.0   \n\n       onehotencoder__emp_length_10+ years  onehotencoder__emp_length_2 years  \\\n0                                      0.0                                0.0   \n1                                      0.0                                0.0   \n2                                      0.0                                1.0   \n3                                      0.0                                0.0   \n4                                      1.0                                0.0   \n...                                    ...                                ...   \n19495                                  1.0                                0.0   \n19496                                  1.0                                0.0   \n19497                                  0.0                                0.0   \n19498                                  0.0                                0.0   \n19499                                  0.0                                0.0   \n\n       ...  remainder__total_rec_int  remainder__total_rec_late_fee  \\\n0      ...                   3359.33                           78.0   \n1      ...                   5302.70                            0.0   \n2      ...                   2148.75                            0.0   \n3      ...                   2109.37                           15.0   \n4      ...                     88.83                            0.0   \n...    ...                       ...                            ...   \n19495  ...                    223.71                            0.0   \n19496  ...                     77.05                            0.0   \n19497  ...                   3020.67                            0.0   \n19498  ...                   3909.77                            0.0   \n19499  ...                     43.26                            0.0   \n\n       remainder__recoveries  remainder__collection_recovery_fee  \\\n0                       0.00                               0.000   \n1                    1614.60                             145.314   \n2                       0.00                               0.000   \n3                     127.05                              22.869   \n4                       0.00                               0.000   \n...                      ...                                 ...   \n19495                   0.00                               0.000   \n19496                   0.00                               0.000   \n19497                   0.00                               0.000   \n19498                   0.00                               0.000   \n19499                   0.00                               0.000   \n\n       remainder__last_pymnt_amnt  remainder__collections_12_mths_ex_med  \\\n0                        16901.45                                    1.0   \n1                          409.95                                    1.0   \n2                        12074.88                                    0.0   \n3                          238.99                                    0.0   \n4                        20101.30                                    0.0   \n...                           ...                                    ...   \n19495                    26244.05                                    0.0   \n19496                     2978.46                                    0.0   \n19497                     2785.60                                    0.0   \n19498                        3.80                                    0.0   \n19499                     1978.17                                    0.0   \n\n       remainder__acc_now_delinq  remainder__tot_coll_amt  \\\n0                            0.0                      0.0   \n1                            0.0                    273.0   \n2                            0.0                      0.0   \n3                            0.0                      0.0   \n4                            0.0                      0.0   \n...                          ...                      ...   \n19495                        0.0                   4812.0   \n19496                        0.0                      0.0   \n19497                        0.0                      NaN   \n19498                        0.0                      0.0   \n19499                        0.0                      0.0   \n\n       remainder__tot_cur_bal  remainder__total_rev_hi_lim  \n0                     70116.0                      43670.0  \n1                     31306.0                      21600.0  \n2                    196318.0                      68900.0  \n3                      6848.0                      16700.0  \n4                    426287.0                      26100.0  \n...                       ...                          ...  \n19495                110260.0                      20600.0  \n19496                260585.0                      46600.0  \n19497                     NaN                          NaN  \n19498                 88348.0                      48000.0  \n19499                 18342.0                      33400.0  \n\n[19500 rows x 50 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 72,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Працюєм з неповними данними\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X_mult_class_ohe_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(ds_ohe))\n",
        "X_mult_class_num_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X_num))\n",
        "y_mult_class  = ds['loan_status']"
      ],
      "outputs": [],
      "execution_count": 73,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_num_mult_class_mean_for_train , X_num_mult_class_mean_for_validation , y_num_mult_class_for_train , y_num_mult_class_for_validation = train_test_split(X_mult_class_num_mean_strategy,y_mult_class,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_num_mult_class_mean_for_train = QuantileTransformer().fit_transform(X_num_mult_class_mean_for_train)\n",
        "X_num_mult_class_mean_for_validation = QuantileTransformer().fit_transform(X_num_mult_class_mean_for_validation)\n",
        "\n",
        "\n",
        "pd.DataFrame(X_num_mult_class_mean_for_train,columns=X_mult_class_num_mean_strategy.columns).describe()\n",
        "\n",
        "\n",
        "\n",
        "# Розділяєм числовий DataFrame на тренувальну та валідаційну вибірку\n",
        "X_ohe_mult_class_mean_for_train , X_ohe_mult_class_mean_for_validation , y_ohe_mult_class_for_train , y_ohe_mult_class_for_validation = train_test_split(X_mult_class_ohe_mean_strategy,y_mult_class,test_size= 0.3,random_state=0)\n",
        "\n",
        "\n",
        "# Трансформуємо ознаки за допомогою QuantileTransformer\n",
        "X_ohe_mult_class_mean_for_train = QuantileTransformer().fit_transform(X_ohe_mult_class_mean_for_train)\n",
        "X_ohe_mult_class_mean_for_validation = QuantileTransformer().fit_transform(X_ohe_mult_class_mean_for_validation)"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import *\n",
        "\n",
        "\n",
        "cv = 3\n",
        "LogisticRegression_mult_class = GridSearchCV(\n",
        "    estimator= LogisticRegression(),\n",
        "    param_grid= {'penalty': ['l1','l2','elasticnet'] , 'C' : np.logspace(-4,4,5), 'solver' : ['saga'],'max_iter' : [100,1000,2500,3000]},\n",
        "    cv = cv,\n",
        "    n_jobs= -1\n",
        ").fit(X_num_mult_class_mean_for_train,y_num_mult_class_for_train)\n",
        "\n",
        "\n",
        "LogisticRegression_X_num_mult_class = pd.DataFrame(LogisticRegression_mult_class.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "LogisticRegression_num_mult_class_best_model = LogisticRegression_mult_class.best_estimator_\n",
        "print(f'average_precision_score для найкращої моделі з на відкладеній вибірці: {average_precision_score(y_num_mult_class_for_validation,LogisticRegression_num_mult_class_best_model.predict_proba(X_num_mult_class_mean_for_validation))}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n60 fits failed out of a total of 180.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\nValueError: l1_ratio must be specified when penalty is elasticnet.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.59274725 0.59274725        nan 0.59274725 0.59274725        nan\n 0.59274725 0.59274725        nan 0.59274725 0.59274725        nan\n 0.81684982 0.81509158        nan 0.81684982 0.81509158        nan\n 0.81684982 0.81509158        nan 0.81684982 0.81509158        nan\n 0.86344322 0.86080586        nan 0.86322344 0.86080586        nan\n 0.86322344 0.86080586        nan 0.86322344 0.86080586        nan\n 0.8640293  0.86417582        nan 0.86410256 0.86417582        nan\n 0.86446886 0.86417582        nan 0.86424908 0.86417582        nan\n 0.86388278 0.86380952        nan 0.86410256 0.86410256        nan\n 0.86446886 0.86446886        nan 0.86424908 0.86424908        nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "average_precision_score для найкращої моделі з на відкладеній вибірці: 0.5441414318539347\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
        }
      ],
      "execution_count": 75,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "cv = 3\n",
        "LogisticRegression_mult_class_ohe = GridSearchCV(\n",
        "    estimator= LogisticRegression(),\n",
        "    param_grid= {'penalty': ['l1','l2','elasticnet'] , 'C' : np.logspace(-4,4,5), 'solver' : ['saga'],'max_iter' : [100,1000,2500,3000]},\n",
        "    cv = cv,\n",
        "    n_jobs= -1\n",
        ").fit(X_ohe_mult_class_mean_for_train,y_ohe_mult_class_for_train)\n",
        "\n",
        "\n",
        "LogisticRegression_X_ohe_mult_class = pd.DataFrame(LogisticRegression_mult_class_ohe.cv_results_).drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time'])\n",
        "\n",
        "LogisticRegression_ohe_mult_class_best_model = LogisticRegression_mult_class_ohe.best_estimator_\n",
        "print(f'average_precision_score для найкращої моделі з на відкладеній вибірці: {average_precision_score(y_ohe_mult_class_for_validation,LogisticRegression_ohe_mult_class_best_model.predict_proba(X_ohe_mult_class_mean_for_validation))}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n60 fits failed out of a total of 180.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\nValueError: l1_ratio must be specified when penalty is elasticnet.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.59274725 0.59274725        nan 0.59274725 0.59274725        nan\n 0.59274725 0.59274725        nan 0.59274725 0.59274725        nan\n 0.81684982 0.8189011         nan 0.81684982 0.8189011         nan\n 0.81684982 0.8189011         nan 0.81684982 0.8189011         nan\n 0.87018315 0.86622711        nan 0.86981685 0.86622711        nan\n 0.86981685 0.86622711        nan 0.86981685 0.86622711        nan\n 0.86967033 0.86989011        nan 0.87003663 0.86981685        nan\n 0.87010989 0.86981685        nan 0.87010989 0.86996337        nan\n 0.86996337 0.86989011        nan 0.86996337 0.86996337        nan\n 0.86996337 0.86996337        nan 0.86996337 0.86996337        nan]\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "average_precision_score для найкращої моделі з на відкладеній вибірці: 0.5518209041058022\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
        }
      ],
      "execution_count": 76,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "SVC_X_num_mult_class = GridSearchCV(\n",
        "    estimator = SVC(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mult_class_mean_for_train,y_num_mult_class_for_train)\n",
        "\n",
        "\n",
        "SVC_X_num_mult_class_cv_results = pd.DataFrame(SVC_X_num_mult_class.cv_results_)\n",
        "\n",
        "SVC_X_num_mult_class = SVC_X_num_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVC_X_num_mult_class_score = average_precision_score(y_num_mult_class_for_validation,SVC_X_num_mult_class.decision_function(X_num_mult_class_mean_for_validation))\n",
        "\n",
        "\n",
        "SVC_X_num_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "0.5025212968548184"
          },
          "metadata": {}
        }
      ],
      "execution_count": 77,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "SVC_X_ohe_mult_class = GridSearchCV(\n",
        "    estimator = SVC(),\n",
        "    param_grid= {'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mult_class_mean_for_train,y_ohe_mult_class_for_train)\n",
        "\n",
        "\n",
        "SVC_X_ohe_mult_class_cv_results = pd.DataFrame(SVC_X_ohe_mult_class.cv_results_)\n",
        "\n",
        "SVC_X_ohe_mult_class = SVC_X_ohe_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "SVC_X_ohe_mult_class_score = average_precision_score(y_ohe_mult_class_for_validation,SVC_X_ohe_mult_class.decision_function(X_ohe_mult_class_mean_for_validation))\n",
        "\n",
        "\n",
        "SVC_X_ohe_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": "0.5171455267993237"
          },
          "metadata": {}
        }
      ],
      "execution_count": 78,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "KNC_X_ohe_mult_class = GridSearchCV(\n",
        "    estimator = KNeighborsClassifier(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mult_class_mean_for_train,y_ohe_mult_class_for_train)\n",
        "\n",
        "\n",
        "KNC_X_ohe_mult_class_cv_results = pd.DataFrame(KNC_X_ohe_mult_class.cv_results_)\n",
        "\n",
        "KNC_X_ohe_mult_class = KNC_X_ohe_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNC_X_ohe_mult_class_score = average_precision_score(y_ohe_mult_class_for_validation,KNC_X_ohe_mult_class.predict_proba(X_ohe_mult_class_mean_for_validation))\n",
        "\n",
        "\n",
        "KNC_X_ohe_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": "0.41107368433750197"
          },
          "metadata": {}
        }
      ],
      "execution_count": 79,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "KNC_X_num_mult_class = GridSearchCV(\n",
        "    estimator = KNeighborsClassifier(),\n",
        "    param_grid= {'weights':['uniform', 'distance'],'algorithm':['ball_tree','auto','kd_tree','brute']},\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mult_class_mean_for_train,y_num_mult_class_for_train)\n",
        "\n",
        "\n",
        "KNC_X_num_mult_class_cv_results = pd.DataFrame(KNC_X_num_mult_class.cv_results_)\n",
        "\n",
        "KNC_X_num_mult_class = KNC_X_num_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "KNC_X_num_mult_class_score = average_precision_score(y_num_mult_class_for_validation,KNC_X_num_mult_class.predict_proba(X_num_mult_class_mean_for_validation))\n",
        "\n",
        "\n",
        "KNC_X_num_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 80,
          "data": {
            "text/plain": "0.46248692533194846"
          },
          "metadata": {}
        }
      ],
      "execution_count": 80,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DTC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "DTC_X_ohe_mult_class = GridSearchCV(\n",
        "    estimator = DecisionTreeClassifier(),\n",
        "    param_grid= {'splitter':['gini', 'entropy','log_loss'],'splitter':['best','random'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mult_class_mean_for_train,y_ohe_mult_class_for_train)\n",
        "\n",
        "\n",
        "DTC_X_ohe_mult_class_cv_results = pd.DataFrame(DTC_X_ohe_mult_class.cv_results_)\n",
        "\n",
        "DTC_X_ohe_mult_class = DTC_X_ohe_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTC_X_ohe_mult_class_score = average_precision_score(y_ohe_mult_class_for_validation,DTC_X_ohe_mult_class.predict_proba(X_ohe_mult_class_mean_for_validation))\n",
        "DTC_X_ohe_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 81,
          "data": {
            "text/plain": "0.3830058023230295"
          },
          "metadata": {}
        }
      ],
      "execution_count": 81,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "DTC_X_num_mult_class = GridSearchCV(\n",
        "    estimator = DecisionTreeClassifier(),\n",
        "    param_grid= {'splitter':['gini', 'entropy','log_loss'],'splitter':['best','random'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mult_class_mean_for_train,y_num_mult_class_for_train)\n",
        "\n",
        "\n",
        "DTC_X_num_mult_class_cv_results = pd.DataFrame(DTC_X_num_mult_class.cv_results_)\n",
        "\n",
        "DTC_X_num_mult_class = DTC_X_num_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "DTC_X_num_mult_class_score = average_precision_score(y_num_mult_class_for_validation,DTC_X_num_mult_class.predict_proba(X_num_mult_class_mean_for_validation))\n",
        "DTC_X_num_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 82,
          "data": {
            "text/plain": "0.3914037799850637"
          },
          "metadata": {}
        }
      ],
      "execution_count": 82,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RFC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "RFC_X_num_mult_class = GridSearchCV(\n",
        "    estimator = RandomForestClassifier(),\n",
        "    param_grid= {'criterion':['gini', 'entropy','log_loss'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_num_mult_class_mean_for_train,y_num_mult_class_for_train)\n",
        "\n",
        "\n",
        "RFC_X_num_mult_class_cv_results = pd.DataFrame(RFC_X_num_mult_class.cv_results_)\n",
        "\n",
        "RFC_X_num_mult_class = RFC_X_num_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFC_X_num_mult_class_score = average_precision_score(y_num_mult_class_for_validation,RFC_X_num_mult_class.predict_proba(X_num_mult_class_mean_for_validation))\n",
        "RFC_X_num_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 83,
          "data": {
            "text/plain": "0.5266887914561587"
          },
          "metadata": {}
        }
      ],
      "execution_count": 83,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "RFC_X_ohe_mult_class = GridSearchCV(\n",
        "    estimator = RandomForestClassifier(),\n",
        "    param_grid= {'criterion':['gini', 'entropy','log_loss'],'max_features':['sqrt','log2']},\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ").fit(X_ohe_mult_class_mean_for_train,y_ohe_mult_class_for_train)\n",
        "\n",
        "\n",
        "RFC_X_ohe_mult_class_cv_results = pd.DataFrame(RFC_X_ohe_mult_class.cv_results_)\n",
        "\n",
        "RFC_X_ohe_mult_class = RFC_X_ohe_mult_class.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "RFC_X_ohe_mult_class_score = average_precision_score(y_ohe_mult_class_for_validation,RFC_X_ohe_mult_class.predict_proba(X_ohe_mult_class_mean_for_validation))\n",
        "RFC_X_ohe_mult_class_score"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/plain": "0.5310470286569527"
          },
          "metadata": {}
        }
      ],
      "execution_count": 84,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Models_task_4 = pd.DataFrame(data = {'Model_Name': ['LogisticRegression_X_num_mult_class','LogisticRegression_X_ohe_mult_class','SVC_X_ohe_mult_class','SVC_X_num_mult_class','KNC_X_ohe_mult_class','KNC_X_num_mult_class','DTC_X_ohe_mult_class','DTC_X_num_mult_class','RFC_X_ohe_mult_class','RFC_X_num_mult_class'],'Model':[LogisticRegression_num_mult_class_best_model,LogisticRegression_ohe_mult_class_best_model,SVC_X_ohe_mult_class,SVC_X_num_mult_class,KNC_X_ohe_mult_class,KNC_X_num_mult_class,DTC_X_ohe_mult_class,DTC_X_num_mult_class,RFC_X_ohe_mult_class,RFC_X_num_mult_class],'average_precision_score':[average_precision_score(y_num_mult_class_for_validation,LogisticRegression_num_mult_class_best_model.predict_proba(X_num_mult_class_mean_for_validation)),average_precision_score(y_ohe_mult_class_for_validation,LogisticRegression_ohe_mult_class_best_model.predict_proba(X_ohe_mult_class_mean_for_validation)),SVC_X_ohe_mult_class_score,SVC_X_num_mult_class_score,KNC_X_ohe_mult_class_score,KNC_X_num_mult_class_score,DTC_X_ohe_mult_class_score,DTC_X_num_mult_class_score,RFC_X_ohe_mult_class_score,RFC_X_num_mult_class_score]})\n",
        "Models_task_4"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_Name</th>\n      <th>Model</th>\n      <th>average_precision_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression_X_num_mult_class</td>\n      <td>LogisticRegression(C=100.0, max_iter=2500, pen...</td>\n      <td>0.544141</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LogisticRegression_X_ohe_mult_class</td>\n      <td>LogisticRegression(penalty='l1', solver='saga')</td>\n      <td>0.551821</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC_X_ohe_mult_class</td>\n      <td>SVC(kernel='linear')</td>\n      <td>0.517146</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVC_X_num_mult_class</td>\n      <td>SVC(kernel='linear')</td>\n      <td>0.502521</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNC_X_ohe_mult_class</td>\n      <td>KNeighborsClassifier(algorithm='ball_tree')</td>\n      <td>0.411074</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNC_X_num_mult_class</td>\n      <td>KNeighborsClassifier(algorithm='ball_tree', we...</td>\n      <td>0.462487</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DTC_X_ohe_mult_class</td>\n      <td>DecisionTreeClassifier(max_features='sqrt')</td>\n      <td>0.383006</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DTC_X_num_mult_class</td>\n      <td>DecisionTreeClassifier(max_features='sqrt')</td>\n      <td>0.391404</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RFC_X_ohe_mult_class</td>\n      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n      <td>0.531047</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RFC_X_num_mult_class</td>\n      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n      <td>0.526689</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                            Model_Name  \\\n0  LogisticRegression_X_num_mult_class   \n1  LogisticRegression_X_ohe_mult_class   \n2                 SVC_X_ohe_mult_class   \n3                 SVC_X_num_mult_class   \n4                 KNC_X_ohe_mult_class   \n5                 KNC_X_num_mult_class   \n6                 DTC_X_ohe_mult_class   \n7                 DTC_X_num_mult_class   \n8                 RFC_X_ohe_mult_class   \n9                 RFC_X_num_mult_class   \n\n                                               Model  average_precision_score  \n0  LogisticRegression(C=100.0, max_iter=2500, pen...                 0.544141  \n1    LogisticRegression(penalty='l1', solver='saga')                 0.551821  \n2                               SVC(kernel='linear')                 0.517146  \n3                               SVC(kernel='linear')                 0.502521  \n4        KNeighborsClassifier(algorithm='ball_tree')                 0.411074  \n5  KNeighborsClassifier(algorithm='ball_tree', we...                 0.462487  \n6        DecisionTreeClassifier(max_features='sqrt')                 0.383006  \n7        DecisionTreeClassifier(max_features='sqrt')                 0.391404  \n8  (DecisionTreeClassifier(max_features='sqrt', r...                 0.531047  \n9  (DecisionTreeClassifier(max_features='sqrt', r...                 0.526689  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 85,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_task4_num = [LogisticRegression_num_mult_class_best_model,SVC_X_num_mult_class,KNC_X_num_mult_class,DTC_X_num_mult_class,RFC_X_num_mult_class]\n",
        "optimal_model_task_4 = Models_task_4[Models_task_4['average_precision_score'] == Models_task_4['average_precision_score'].values.max()]['Model'].values[0]"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('predict.csv')\n",
        "\n",
        "\n",
        "# Функція яка приведе зовнішній датасет до вигляду, який приймає рішаюча модель\n",
        "def transform_test_data(model,test):\n",
        "    \n",
        "    \n",
        "    if (model in best_models_task4_num):\n",
        "        test_X_num_mean_strategy = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(test[nums_features]))\n",
        "        test = QuantileTransformer().fit_transform(test_X_num_mean_strategy)\n",
        "        prediction =  label_encoder.inverse_transform(model.predict(test))\n",
        "        return prediction\n",
        "    \n",
        "    \n",
        "    else:\n",
        "        from sklearn.compose import make_column_transformer\n",
        "        from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
        "\n",
        "        text_features_test = [i for i in test.columns if type(test[i][0]) == str]\n",
        "        nums_features_test = [i for i in test.columns if i not in text_features]\n",
        "        columns_ohe_test = make_column_transformer(\n",
        "            ( OneHotEncoder(handle_unknown='ignore',sparse_output=False) ,text_features_test),\n",
        "            remainder = 'passthrough'\n",
        "        ).set_output(transform='pandas')\n",
        "        test = columns_ohe_test.fit_transform(test)\n",
        "        test = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(test))\n",
        "        test = QuantileTransformer().fit_transform(test)\n",
        "        prediction = label_encoder.inverse_transform(model.predict(test))\n",
        "        return prediction\n",
        "\n",
        "\n",
        "\n",
        "best_reg_model_predictions =  transform_test_data(optimal_model_task_4,test)\n",
        "\n",
        "\n",
        "\n",
        "pd.Series(best_reg_model_predictions).to_csv('predictions_clf.csv')\n"
      ],
      "outputs": [],
      "execution_count": 87,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_reg_model_predictions =  transform_test_data(optimal_model_task_4,test)"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Висновок задача 5-класова красифікації\n",
        " Модель(з відповідними парамптрами) збережена у змінну optimal_model_task_4 модель , має найкращий average_precision_score на відкладеній вибірці, а одже і є найкращою моделлю для вирішення пятикласової красифікації."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}